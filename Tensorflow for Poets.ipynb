{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Script and code copied from:\n",
    "https://codelabs.developers.google.com/codelabs/tensorflow-for-poets/#0  \n",
    "Only small changes to use Jupyter  \n",
    "Licensed under Apache V2.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Installing Tensorflow\n",
    "I use Python Anaconda on Windows with Python 3.5.x and installed Tensorflow libraries manually:  \n",
    "Python Anaconda: https://www.continuum.io/downloads  \n",
    "Tensorflow: https://www.tensorflow.org/install/install_windows  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model\n",
    "\n",
    "Getting training data and training script. I used Cygwin to execute the code but you can download and extract this manually:  \n",
    "\n",
    "Get Images:\n",
    "<code>\n",
    "curl -O http://download.tensorflow.org/example_images/flower_photos.tgz  \n",
    "tar xzf flower_photos.tgz  \n",
    "\n",
    "</code>\n",
    "Get training script retrain.py:\n",
    "<code>\n",
    "curl -O https://raw.githubusercontent.com/tensorflow/tensorflow/r1.1/tensorflow/examples/image_retraining/retrain.py\n",
    "</code>\n",
    "You might want to look at the script to see whats going on under the hood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import urllib.request\n",
    "import tensorflow as tf\n",
    "from IPython.display import Image\n",
    "\n",
    "import retrain  # the Tensorflow script retrain.py we downloaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# default values\n",
    "# For the meaning of these values look at retrain.py:\n",
    "FLAGS = argparse.Namespace()\n",
    "\n",
    "FLAGS.image_dir = \"\"\n",
    "FLAGS.output_graph = '.\\\\retrained_graph.pb'\n",
    "FLAGS.output_labels = '.\\\\output_labels.txt'\n",
    "FLAGS.summaries_dir = '.\\\\summaries'\n",
    "FLAGS.how_many_training_steps = 4000\n",
    "FLAGS.learning_rate = 0.01\n",
    "FLAGS.testing_percentage = 10\n",
    "FLAGS.validation_percentage = 10\n",
    "FLAGS.eval_step_interval = 10\n",
    "FLAGS.train_batch_size = 100\n",
    "FLAGS.test_batch_size = -1\n",
    "FLAGS.validation_batch_size = 100\n",
    "FLAGS.print_misclassified_test_images = False\n",
    "FLAGS.model_dir = \".\"\n",
    "FLAGS.bottleneck_dir = \"bottlenecks\"\n",
    "FLAGS.final_tensor_name = \"final_result\"\n",
    "FLAGS.flip_left_right = False\n",
    "FLAGS.random_crop = 0\n",
    "FLAGS.random_scale = 0\n",
    "FLAGS.random_brightness = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# change default: \n",
    "FLAGS.how_many_training_steps = 500\n",
    "FLAGS.model_dir = \"inception\"\n",
    "# FLAGS.summaries_dir = \"C:\\\\to\\\\temp\" \n",
    "FLAGS.output_graph = \"retrained_graph_v2.pb\"  \n",
    "FLAGS.output_labels = \"retrained_labels.txt\"\n",
    "FLAGS.image_dir = \"flower_photos\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrain model on the flower photos. Depending on your parameters and your hardware this can take up to one hour or even longer. Decent PC should handle this in less than 30 minutes. The script will create additional folders and files on your drive for the model, logging and performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "retrain.FLAGS = FLAGS\n",
    "tf.app.run(main=retrain.main)  # this is basically same as retrain.main(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test model on new pictures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Read in the image_data\n",
    "\n",
    "# test_image_path = \".\\\\test_flowers\\\\dandelion.jpg\"  # uncomment this if you want to use a local file\n",
    "# test_image_path = \"https://upload.wikimedia.org/wikipedia/commons/4/44/Tulip_-_floriade_canberra.jpg\"\n",
    "test_image_path = \"https://codelabs.developers.google.com/codelabs/tensorflow-for-poets/img/3021186b83bc90c2.png\"\n",
    "\n",
    "if test_image_path[:4] == \"http\":  # assuming URL\n",
    "    image_data = urllib.request.urlopen(test_image_path).read()\n",
    "else:  # assuming file path\n",
    "    image_data = tf.gfile.FastGFile(test_image_path, 'rb').read() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "daisy (score = 0.98726)\n",
      "sunflowers (score = 0.01056)\n",
      "dandelion (score = 0.00152)\n",
      "tulips (score = 0.00063)\n",
      "roses (score = 0.00003)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<img src=\"https://codelabs.developers.google.com/codelabs/tensorflow-for-poets/img/3021186b83bc90c2.png\" width=\"100\" height=\"100\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "# Loads label file, strips off carriage return\n",
    "label_lines = [line.rstrip() for line \n",
    "                   in tf.gfile.GFile(FLAGS.output_labels)]\n",
    "\n",
    "# Unpersists graph from file\n",
    "with tf.gfile.FastGFile(FLAGS.output_graph, 'rb') as f:\n",
    "    graph_def = tf.GraphDef()\n",
    "    graph_def.ParseFromString(f.read())\n",
    "    tf.import_graph_def(graph_def, name='')\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # Feed the image_data as input to the graph and get first prediction\n",
    "    softmax_tensor = sess.graph.get_tensor_by_name('final_result:0')\n",
    "    \n",
    "    predictions = sess.run(softmax_tensor, \\\n",
    "             {'DecodeJpeg/contents:0': image_data})\n",
    "    \n",
    "    # Sort to show labels of first prediction in order of confidence\n",
    "    top_k = predictions[0].argsort()[-len(predictions[0]):][::-1]\n",
    "    \n",
    "    for node_id in top_k:\n",
    "        human_string = label_lines[node_id]\n",
    "        score = predictions[0][node_id]\n",
    "        print('%s (score = %.5f)' % (human_string, score))\n",
    "\n",
    "# Output image in Jupyter\n",
    "Image(url=test_image_path, width=100, height=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
